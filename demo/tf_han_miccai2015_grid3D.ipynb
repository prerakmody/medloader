{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Imports"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "from pathlib import Path\n",
    "\n",
    "import medloader.dataloader.utils as utils\n",
    "import medloader.dataloader.config as config\n",
    "import medloader.dataloader.utils_viz as utils_viz\n",
    "import medloader.dataloader.tensorflow.augmentations as aug\n",
    "from medloader.dataloader.tensorflow.dataset import ZipDataset\n",
    "\n",
    "MAIN_DIR = Path().resolve().parent.absolute()\n",
    "data_dir = Path(MAIN_DIR).joinpath('data')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "source": [
    "# Functions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_han_miccai2015_3D_grid(data_dir, dir_type\n",
    "            , mask_type, resampled=False\n",
    "            , transforms=True, filter=True, debug=False):\n",
    "    \n",
    "    from medloader.dataloader.tensorflow.han_miccai2015_grid import HaNMICCAI2015Dataset\n",
    "\n",
    "    # Step 1 - Get dataset class\n",
    "    dataset = HaNMICCAI2015Dataset(data_dir=data_dir, dir_type=dir_type\n",
    "                    , dimension=3, mask_type=mask_type, resampled=resampled\n",
    "                    , filter=True\n",
    "                    , debug=debug)\n",
    "\n",
    "    # Step 2 - Transforms\n",
    "    if transforms:\n",
    "        x_shape_w = dataset.w_grid\n",
    "        x_shape_h = dataset.h_grid\n",
    "        x_shape_d = dataset.d_grid\n",
    "        transforms = [\n",
    "                aug.NormalizeMinMaxSampler(min_val=config.HU_MIN, max_val=config.HU_MAX, x_shape=(x_shape_h, x_shape_w, x_shape_d,1))\n",
    "                , aug.Rotate3D()\n",
    "            ]\n",
    "        dataset.transforms = transforms\n",
    "\n",
    "    # Step 3 - Filters (to eliminate/reduce background-only grids)\n",
    "    if filter:\n",
    "        dataset.filter = aug.FilterByMask(len(dataset.LABEL_MAP), dataset.SAMPLER_PERC).execute\n",
    "\n",
    "    return ZipDataset([dataset])"
   ]
  },
  {
   "source": [
    "# Main - for ML purposes (a Tensorflow loader)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batchsize = 1\n",
    "dataset3D = get_dataset_han_miccai2015_3D_grid(data_dir=data_dir, dir_type='train'\n",
    "                                            , mask_type=config.MASK_TYPE_ONEHOT, resampled=False\n",
    "                                            , filter=True)\n",
    "\n",
    "try:\n",
    "    for (X,Y,meta1,meta2) in dataset3D.generator().batch(batchsize):\n",
    "        print (X.shape, Y.shape, meta1.numpy())\n",
    "        pbd.set_trace()\n",
    "except:\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "source": [
    "# Main - for ML benchmarking purposes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "AlreadyExistsError",
     "evalue": "Another profiler is running.",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAlreadyExistsError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-b71a0a235b59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# utils.benchmark(dataset3D.generator().batch(batchsize), model_time=0.3)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbenchmark_with_profiler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset3D\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_time\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/data/ppmody/code/medloader/medloader/dataloader/utils.py\u001b[0m in \u001b[0;36mbenchmark_with_profiler\u001b[0;34m(dataset_generator, model_time)\u001b[0m\n\u001b[1;32m    896\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'2.3.0'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 898\u001b[0;31m         \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./logdir'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    899\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m' - [utils.benchmark_with_profiler()]'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m         \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/data/anaconda3/envs/medloader/lib/python3.7/site-packages/tensorflow/python/profiler/profiler_v2.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(logdir, options)\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_profiler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m       raise errors.AlreadyExistsError(None, None,\n\u001b[0;32m--> 106\u001b[0;31m                                       'Another profiler is running.')\n\u001b[0m\u001b[1;32m    107\u001b[0m     \u001b[0m_profiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_pywrap_profiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProfilerSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAlreadyExistsError\u001b[0m: Another profiler is running."
     ]
    }
   ],
   "source": [
    "\n",
    "import medloader.dataloader.utils as utils\n",
    "\n",
    "batchsize = 1\n",
    "dataset3D = get_dataset_han_miccai2015_3D_grid(data_dir=data_dir, dir_type='train'\n",
    "                                            , mask_type=config.MASK_TYPE_ONEHOT, resampled=True\n",
    "                                            , filter=True, transforms=True)\n",
    "\n",
    "# utils.benchmark(dataset3D.generator().batch(batchsize), model_time=0.3)\n",
    "utils.benchmark_with_profiler(dataset3D.generator().batch(batchsize), model_time=0.3)"
   ]
  },
  {
   "source": [
    "# Main - For Viewing Purposes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAIN_DIR = Path().resolve().parent.absolute()\n",
    "data_dir = Path(MAIN_DIR).joinpath('data')\n",
    "\n",
    "\n",
    "batchsize = 1\n",
    "dataset3D = get_dataset_han_miccai2015_3D_grid(data_dir=data_dir, dir_type='train'\n",
    "                                            , mask_type=config.MASK_TYPE_COMBINED, resampled=False\n",
    "                                            , filter=True, transforms=False)\n",
    "\n",
    "for (X,Y,meta1,meta2) in dataset3D.generator().batch(batchsize):\n",
    "    print (' - ', X.shape, Y.shape, meta1.numpy())\n",
    "    if len(Y.shape) == 4:\n",
    "        datasets_this = utils.get_dataset_from_zip(meta2, dataset3D)\n",
    "        utils_viz.viz_3d_mask(Y, datasets_this, meta1, meta2)\n",
    "        pdb.set_trace()"
   ]
  }
 ]
}